---
title: "Prep for Anya and Wanshu"
author: "G. Moroz"
date: "3/23/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


[source code on GitHub](https://github.com/agricolamz/prep_for_anya_and_wanshu)

# Libraries

```{r}
library(tidyverse)
library(tidytext)
theme_set(theme_bw()) # for visualising
```

* `tidyverse` - a package with packages (most important for us are `readr`, `dplyr`, `ggplot2`, `stringr`)
* `tidytext` -- is a nice package for the text analysis, see the [online book](https://www.tidytextmining.com/) by Julia Silge and David Robinson.

# Files

Donwload the script and the file with the dictionary (I prefer work with columns from B to O, so it is better to remove the rest) and put them in the separate folder. E. g. there are two files in the current folder:

```{r}
list.files()
```

Read file into R:

```{r read_file, cache=TRUE}
read_csv("andic_dicts.csv") %>% 
  filter(glottocode != "toki1238") ->
  andic
```

Have a look:
```{r}
glimpse(andic)
```

# Extract singleton segment frequencies

Convert dataset to the table with one segment per row:

```{r}
andic %>%
  filter(is.na(bor)) %>% 
  mutate(glottocode = ifelse(glottocode == "botl1242", str_c(glottocode, " ", reference), glottocode)) %>% 
  distinct(ipa, glottocode) %>% 
  mutate(id = 1:n()) %>% 
  unnest_tokens(output = "segment", input = ipa, token = stringr::str_split, pattern = "-", drop = FALSE) %>% 
  filter(!is.na(segment)) ->
  unnested_andic
glimpse(unnested_andic)
```


In case we want to change something in our segments, use `case_when` and create a new dataframe, e. g. `unnested_andic_front_back`.

```{r}
unnested_andic %>% 
  filter(!str_detect(segment, "[aoiue]")) %>%
  mutate(segment = case_when(
    str_detect(segment, "[ie]") ~ "front",
    str_detect(segment, "a") ~ "mid",
    str_detect(segment, "[uo]") ~ "back")) ->
  unnested_andic_front_back
```


Extract singleton segment frequencies

```{r}
unnested_andic %>% 
  count(glottocode, segment) %>% 
  group_by(glottocode) %>% 
  mutate(overall = sum(n),
         ratio = n/overall) ->
  segment_frequency_by_lang_long_format
glimpse(segment_frequency_by_lang_long_format)
```

We can look at it:

```{r}
segment_frequency_by_lang_long_format %>% 
  select(-n, -overall) %>% 
  pivot_wider(names_from = glottocode, values_from = ratio)
```

Or even try to visualize:

```{r}
segment_frequency_by_lang_long_format %>% 
  group_by(segment) %>%  # this and next 3 lines are for ordering segments
  mutate(mean_ratio = mean(ratio, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(segment = fct_reorder(segment, mean_ratio)) %>% 
  top_n(100) %>% 
  ggplot(aes(ratio, segment, color = glottocode))+
  geom_point()

segment_frequency_by_lang_long_format %>% 
  mutate(segment = reorder_within(segment, ratio, glottocode)) %>% 
  group_by(glottocode) %>% 
  top_n(25) %>% 
  ggplot(aes(ratio, segment))+
  geom_point()+
  facet_wrap(~glottocode, scales = "free_y")+
  scale_y_reordered()
```

You can even filter some vowels/consononats
```{r}
segment_frequency_by_lang_long_format %>% 
  filter(str_detect(segment, "[aoiue]")) %>% 
  mutate(segment = reorder_within(segment, ratio, glottocode)) %>% 
  group_by(glottocode) %>% 
  top_n(25) %>% 
  ggplot(aes(ratio, segment))+
  geom_point()+
  facet_wrap(~glottocode, scales = "free_y")+
  scale_y_reordered()

segment_frequency_by_lang_long_format %>% 
  filter(str_detect(segment, "[^aoiue]")) %>% 
  mutate(segment = reorder_within(segment, ratio, glottocode)) %>% 
  group_by(glottocode) %>% 
  top_n(25) %>% 
  ggplot(aes(ratio, segment))+
  geom_point()+
  facet_wrap(~glottocode, scales = "free_y")+
  scale_y_reordered()
```

# Extract combined segment frequencies

There are two types of combined segment frequencies:

* **["bag of words"](https://en.wikipedia.org/wiki/Bag-of-words_model) approach**:  simple calculation number of words that have selected pair of sounds
* **[markov chain](https://en.wikipedia.org/wiki/Markov_chain) approach** more like Markov Chain approach, where you model number of cases when one segment is following another

For a moment I will work with the first option, but lets keep the second in mind.

## "Bag of words" approach

```{r unnesting, cache=TRUE}
unnested_andic %>% 
#   filter(str_detect(segment, "[aoiue]")) %>%  # uncomment in order to select just vowels/consonants
  distinct(ipa, glottocode, segment) %>% # remove repetitions
  nest(data = segment) %>% 
  mutate(data = map(data, unlist),
         data = map(data, sort), # prevent from different orderings within the pair
         length = map_dbl(data, length)) %>% 
  filter(length > 1) %>% 
  mutate(pairs = map(data, combn, m = 2, FUN = str_c, collapse = " ")) %>% 
  unnest_longer(pairs) %>% 
  count(glottocode, pairs, sort = TRUE) %>% 
  separate(pairs, into = c("segment_1", "segment_2"), sep = " ", remove = FALSE) ->
  pairs
```

```{r}
glimpse(pairs)

pairs %>% 
  group_by(glottocode) %>% 
  mutate(overall = sum(n),
         ratio = n/overall) %>% 
  top_n(20) %>% 
  mutate(pairs = reorder_within(pairs, ratio, glottocode)) %>% 
  ggplot(aes(ratio, pairs))+
  geom_point()+
  facet_wrap(~glottocode, scales = "free")+
  scale_y_reordered()
```

Remember that order in each pair does not reflect order in the word, otherwise we could have deal with pairs with different order (a-r vs r-a). You can uncomment `#   filter(str_detect(segment, "[aoiue]")) %>%` row and get info by vowels/consonants.

## Markov chain approach

Since in this approach we want to model changes from one segment to another, the easiest way to do it is to add hash sign `#`, that denotes the end of the word.

```{r unnesting2, cache = TRUE}
andic %>%
  filter(is.na(bor)) %>% 
  mutate(glottocode = ifelse(glottocode == "botl1242", str_c(glottocode, " ", reference), glottocode)) %>% 
  distinct(ipa, glottocode) %>% 
  mutate(id = 1:n(),
         ipa = str_c(ipa, "-#")) %>% 
  unnest_tokens(output = "segment", input = ipa, token = stringr::str_split, pattern = "-", drop = FALSE) %>% 
  filter(!is.na(segment)) %>% 
  mutate(next_segment = lead(segment)) %>% 
  filter(segment != "#",
         next_segment != "#") %>% 
  count(glottocode, segment, next_segment) ->
  unnested_andic_with_hash
```

And now we can do more or less the same vizualisations as in previous section:

```{r}
unnested_andic_with_hash %>% 
  mutate(pairs = str_c(segment, " ", next_segment)) %>% 
  group_by(glottocode) %>% 
  mutate(overall = sum(n),
         ratio = n/overall) %>% 
  top_n(20) %>% 
  mutate(pairs = reorder_within(pairs, ratio, glottocode)) %>% 
  ggplot(aes(ratio, pairs))+
  geom_point()+
  facet_wrap(~glottocode, scales = "free")+
  scale_y_reordered()
```

As expected results are really different!


Let's analyze features:

```{r}
andic %>%
  filter(is.na(bor)) %>% 
  mutate(glottocode = ifelse(glottocode == "botl1242", str_c(glottocode, " ", reference), glottocode)) %>% 
  distinct(ipa, glottocode) %>% 
  mutate(id = 1:n(),
         ipa = str_c(ipa, "-#")) %>% 
  unnest_tokens(output = "segment", input = ipa, token = stringr::str_split, pattern = "-", drop = FALSE) %>% 
  filter(!is.na(segment),
         str_detect(segment, "[aiuoe]")) %>% 
  mutate(segment = case_when(
    str_detect(segment, "[ie]") ~ "front",
    str_detect(segment, "a") ~ "mid",
    str_detect(segment, "[uo]") ~ "back")) %>% 
  mutate(next_segment = lead(segment)) %>% 
  filter(segment != "#",
         next_segment != "#") %>% 
  count(glottocode, segment, next_segment) ->
  unnested_andic_with_hash_back_front

unnested_andic_with_hash_back_front %>% 
  mutate(pairs = str_c(segment, " ", next_segment)) %>% 
  group_by(glottocode) %>% 
  mutate(overall = sum(n),
         ratio = n/overall) %>% 
  top_n(20) %>% 
  mutate(pairs = reorder_within(pairs, ratio, glottocode)) %>% 
  ggplot(aes(ratio, pairs))+
  geom_point()+
  facet_wrap(~glottocode, scales = "free")+
  scale_y_reordered()
```

# Combine everything

So for now we have tow tables:


* `pairs` ("Bag of words" approach)

```{r}
pairs %>% 
  slice(1:5)
```


* `unnested_andic_with_hash` (Markov-chain approach)

```{r}
unnested_andic_with_hash %>% 
  slice(1:5)
```


Lets create a dataframe with pure probabilities:

```{r}
unnested_andic %>% 
  count(glottocode, segment) %>% 
  rename(raw_n = n) ->
  pure_probabilities
```


We want to combine them together and connect with pure probabilities:

```{r, fig.height=12}
pairs %>% 
  select(-pairs) %>% 
  rename(segment = segment_1,
         next_segment = segment_2,
         n_bw = n) %>% 
  full_join(unnested_andic_with_hash) %>% 
  rename(n_mc = n) %>% 
  full_join(pure_probabilities) %>% 
  rename(n1 = raw_n) %>% 
  full_join(pure_probabilities, by = c("glottocode" = "glottocode", "next_segment" = "segment")) %>% 
  rename(n2 = raw_n) %>% 
  group_by(glottocode) %>% 
  mutate(bw = n_bw/sum(n_bw, na.rm = TRUE),
         mc = n_mc/sum(n_mc, na.rm = TRUE),
         expected_probabilities = (n1/sum(n1, na.rm = TRUE))*(n2/sum(n2, na.rm = TRUE))) %>% 
  select(-n_bw, -n_mc, -n1, -n2) %>% 
  pivot_longer(names_to = "approach", values_to = "observed_probabilities", bw:mc) %>% 
  mutate(pair = str_c(segment, " ", next_segment)) %>% 
  ggplot(aes(observed_probabilities, expected_probabilities, label = pair))+
  geom_abline(slope = 1, intercept = 1, linetype = 2)+
  geom_text()+
  facet_grid(glottocode~approach, scales = "free")+
  scale_x_log10()+
  scale_y_log10()
```

We can't see anything, so I'd rather specify something:

```{r}
andic %>%
  mutate(stress_count = str_count(ipa, "'")) %>% 
  filter(is.na(bor),
         !str_detect(lemma, " "),
         stress_count < 2) %>% 
  mutate(glottocode = ifelse(glottocode == "botl1242", str_c(glottocode, " ", reference), glottocode)) %>% 
  distinct(ipa, glottocode) %>% 
  mutate(id = 1:n(),
         ipa = str_c(ipa, "-#")) %>% 
  unnest_tokens(output = "segment", input = ipa, token = stringr::str_split, pattern = "-", drop = FALSE) %>% 
  filter(!is.na(segment)) %>% 
  filter(str_detect(segment, "[aiuoe#]"))  %>%  # HERE IS YOUR FILTER add hashǃ
  mutate(segment = str_remove_all(segment, "['ˌ]")) ->
  filtered_unnested_andic

filtered_unnested_andic %>% 
  count(glottocode, segment) %>% 
  rename(raw_n = n) ->
  pure_probabilities

filtered_unnested_andic %>% 
  distinct(ipa, glottocode, segment) %>% # remove repetitions
  nest(data = segment) %>% 
  mutate(data = map(data, unlist),
         data = map(data, sort), # prevent from different orderings within the pair
         length = map_dbl(data, length)) %>% 
  filter(length > 1) %>% 
  mutate(pairs = map(data, combn, m = 2, FUN = str_c, collapse = " ")) %>% 
  unnest_longer(pairs) %>% 
  count(glottocode, pairs, sort = TRUE) %>% 
  separate(pairs, into = c("segment_1", "segment_2"), sep = " ", remove = FALSE) ->
  pairs

filtered_unnested_andic %>% 
  mutate(next_segment = lead(segment)) %>% 
  filter(segment != "#",
         next_segment != "#") %>% 
  count(glottocode, segment, next_segment) ->
  unnested_andic_with_hash

pairs %>% 
  select(-pairs) %>% 
  rename(segment = segment_1,
         next_segment = segment_2,
         n_bw = n) %>% 
  full_join(unnested_andic_with_hash) %>% 
  rename(n_mc = n) %>% 
  full_join(pure_probabilities) %>% 
  rename(n1 = raw_n) %>% 
  full_join(pure_probabilities, by = c("glottocode" = "glottocode", "next_segment" = "segment")) %>% 
  filter(segment != "#",
         next_segment != "#") %>% 
  rename(n2 = raw_n) %>% 
  group_by(glottocode) %>% 
  mutate(bw = n_bw/sum(n_bw, na.rm = TRUE),
         mc = n_mc/sum(n_mc, na.rm = TRUE),
         expected_probabilities = (n1/sum(n1, na.rm = TRUE))*(n2/sum(n2, na.rm = TRUE))) %>% 
  select(-n_bw, -n_mc, -n1, -n2) %>% 
  pivot_longer(names_to = "approach", values_to = "observed_probabilities", bw:mc) %>% 
  mutate(pair = str_c(segment, " ", next_segment)) ->
  for_plot

map(unique(for_plot$glottocode), function(x){
  for_plot %>% 
    filter(glottocode == {{x}}) %>% 
    ggplot(aes(observed_probabilities, expected_probabilities, label = pair))+
    #geom_abline(slope = 1, intercept = 1, linetype = 2)+
    geom_smooth(method = "lm", se = FALSE, linetype = 2)+
    geom_point()+
    ggrepel::geom_text_repel()+
    facet_wrap(~approach, scales = "free")+
    scale_x_log10()+
    scale_y_log10()+
    labs(title = x,
         x = "observed frequencies",
         y = "expected frequencies")
  ggsave(str_c("vowels_", x, ".png"), width = 11) # you can change vowels to something
})
```

