---
title: "Prep for Anya and Wanshu"
author: "G. Moroz"
date: "3/23/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
editor_options: 
  chunk_output_type: console
---

```{r, include=FALSE}
knitr::opts_chunk$set(message = FALSE)
```


[source code on GitHub](https://github.com/agricolamz/prep_for_anya_and_wanshu)

# Libraries

```{r}
library(tidyverse)
library(tidytext)
theme_set(theme_bw()) # for visualising
```

* `tidyverse` - a package with packages (most important for us are `readr`, `dplyr`, `ggplot2`, `stringr`)
* `tidytext` -- is a nice package for the text analysis, see the [online book](https://www.tidytextmining.com/) by Julia Silge and David Robinson.

# Files

Donwload the script and the file with the dictionary (I prefer work with columns from B to O, so it is better to remove the rest) and put them in the separate folder. E. g. there are two files in the current folder:

```{r}
list.files()
```

Read file into R:

```{r read_file, cache=TRUE}
read_csv("andic_dicts.csv") %>% 
  filter(glottocode != "toki1238") ->
  andic
```

Have a look:
```{r}
glimpse(andic)
```

# Extract singleton segment frequencies

Convert dataset to the table with one segment per row:

```{r}
andic %>%
  filter(is.na(bor)) %>% 
  mutate(glottocode = ifelse(glottocode == "botl1242", str_c(glottocode, " ", reference), glottocode)) %>% 
  distinct(ipa, glottocode) %>% 
  mutate(id = 1:n()) %>% 
  unnest_tokens(output = "segment", input = ipa, token = stringr::str_split, pattern = "-", drop = FALSE) %>% 
  filter(!is.na(segment)) ->
  unnested_andic
glimpse(unnested_andic)
```


In case we want to change something in our segments, use `case_when` and create a new dataframe, e. g. `unnested_andic_front_back`.

```{r}
unnested_andic %>% 
  # THIS IS CAUSE OF MULTIPLE TRUBLES!!! (30.09.2021)
  #distinct(ipa, glottocode, segment) %>% # remove repetitions
  filter(str_detect(segment, "[aoiue]")) %>%
  mutate(segment2 = case_when(
    str_detect(segment, "[ie]") ~ "front",
    str_detect(segment, "a") ~ "mid",
    str_detect(segment, "[uo]") ~ "back")) ->
  unnested_andic_featured
glimpse(unnested_andic_featured)
```

Extract singleton segment frequencies

```{r}
unnested_andic_featured %>% 
  count(glottocode, segment2) %>% 
  group_by(glottocode) %>% 
  mutate(overall = sum(n),
         ratio = n/overall) ->
  unnested_andic_featured_frequencies
glimpse(unnested_andic_featured_frequencies)
```

We can look at it:

```{r}
unnested_andic_featured_frequencies %>% 
  select(-n, -overall) %>% 
  pivot_wider(names_from = glottocode, values_from = ratio)
```

Or even try to visualize:

```{r}
unnested_andic_featured_frequencies %>% 
  group_by(segment2) %>%  # this and next 3 lines are for ordering segments
  mutate(mean_ratio = mean(ratio, na.rm = TRUE)) %>% 
  ungroup() %>% 
  mutate(segment2 = fct_reorder(segment2, mean_ratio)) %>% 
  top_n(100) %>% 
  ggplot(aes(ratio, segment2, color = glottocode))+
  geom_point()

unnested_andic_featured_frequencies %>% 
  mutate(segment2 = reorder_within(segment2, ratio, glottocode)) %>% 
  group_by(glottocode) %>% 
  top_n(25) %>% 
  ggplot(aes(ratio, segment2))+
  geom_point()+
  facet_wrap(~glottocode, scales = "free_y")+
  scale_y_reordered()
```

# Extract combined segment frequencies

There are two types of combined segment frequencies:

* **["bag of words"](https://en.wikipedia.org/wiki/Bag-of-words_model) approach**:  simple calculation number of words that have selected pair of sounds
* **[markov chain](https://en.wikipedia.org/wiki/Markov_chain) approach** more like Markov Chain approach, where you model number of cases when one segment is following another

For a moment I will work with the first option, but lets keep the second in mind.

## "Bag of words" approach

```{r unnesting, cache=TRUE}
unnested_andic_featured %>%
  select(-segment) %>% 
  group_by(glottocode, ipa) %>%
  nest(data = segment2) %>% 
  mutate(data = map(data, unlist),
         data = map(data, table),
         data2 = map(data, names),
         data2 = map(data2, unlist),
         data = map(data, function(x) x[x > 1]),
         data = map(data, names),
         data3 = map2(data, data2, function(x, y){c(unlist(x), unlist(y))}),
         data3 = map(data3, sort),
         length = map_dbl(data3, length)) %>% 
  filter(length > 1) %>% 
  mutate(pairs = map(data3, combn, m = 2, FUN = str_c, collapse = " "),
         pairs = map(pairs, unique)) %>% 
  unnest_longer(pairs) %>% 
  ungroup() %>% 
  count(glottocode, pairs, sort = TRUE) %>% 
  separate(pairs, into = c("segment_1", "segment_2"), sep = " ", remove = FALSE) ->
  pairs
```

```{r}
glimpse(pairs)

pairs %>% 
  group_by(glottocode) %>% 
  mutate(overall = sum(n),
         ratio = n/overall) %>% 
  top_n(20) %>% 
  mutate(pairs = reorder_within(pairs, ratio, glottocode)) %>% 
  ggplot(aes(ratio, pairs))+
  geom_point()+
  facet_wrap(~glottocode, scales = "free")+
  scale_y_reordered()
```

Remember that order in each pair does not reflect order in the word, otherwise we could have deal with pairs with different order (a-r vs r-a). It is important to have a good `unnested_andic_featured` dataframe: you need to filter out consonant/vowels and create the correct `segment2` column.

## Markov chain approach

Since in this approach we want to model changes from one segment to another, the easiest way to do it is to add hash sign `#`, that denotes the end of the word.

```{r unnesting2, cache = TRUE}
andic %>%
  filter(is.na(bor)) %>% 
  mutate(glottocode = ifelse(glottocode == "botl1242", str_c(glottocode, " ", reference), glottocode)) %>% 
  distinct(ipa, glottocode) %>% 
  mutate(id = 1:n(),
         ipa = str_c(ipa, "-#")) %>% 
  unnest_tokens(output = "segment", input = ipa, token = stringr::str_split, pattern = "-", drop = FALSE) %>% 
  filter(!is.na(segment)) %>% 
  filter(str_detect(segment, "[aoiue\\#]")) %>%
  mutate(segment = case_when(
    str_detect(segment, "[ie]") ~ "front",
    str_detect(segment, "a") ~ "mid",
    str_detect(segment, "[uo]") ~ "back",
    str_detect(segment, "\\#") ~ "#")) %>% 
  mutate(next_segment = lead(segment)) %>% 
  filter(segment != "#",
         next_segment != "#") %>% 
  count(glottocode, segment, next_segment) ->
  unnested_andic_featured_with_hash
```

And now we can do more or less the same vizualisations as in previous section:

```{r}
unnested_andic_featured_with_hash %>% 
  mutate(pairs = str_c(segment, " ", next_segment)) %>% 
  group_by(glottocode) %>% 
  mutate(overall = sum(n),
         ratio = n/overall) %>% 
  top_n(20) %>% 
  mutate(pairs = reorder_within(pairs, ratio, glottocode)) %>% 
  ggplot(aes(ratio, pairs))+
  geom_point()+
  facet_wrap(~glottocode, scales = "free")+
  scale_y_reordered()
```

# Combine everything

So for now we have tow tables:


* `pairs` ("Bag of words" approach)

```{r}
pairs %>% 
  slice(1:5)
```


* `unnested_andic_with_hash` (Markov-chain approach)

```{r}
unnested_andic_featured_with_hash %>% 
  slice(1:5)
```


Lets create a dataframe with pure counts:

```{r}
unnested_andic_featured %>% 
  count(glottocode, segment2) %>% 
  rename(raw_n = n,
         segment = segment2) %>% 
  group_by(glottocode) %>% 
  mutate(frequency = raw_n/sum(raw_n)) %>% 
  select(-raw_n) ->
  pure_counts
```


We want to combine them together and connect with pure probabilities:

```{r}
pairs %>% 
  rename(segment = segment_1,
         next_segment = segment_2) %>% 
  full_join(pure_counts) %>% 
  rename(f1 = frequency) %>% 
  full_join(pure_counts, by = c("glottocode" = "glottocode", "next_segment" = "segment")) %>% 
  rename(f2 = frequency) %>% 
  group_by(glottocode) %>% 
  mutate(observed_probability = n/sum(n, na.rm = TRUE),
         multiply = segment != next_segment,
         expected_probability = f1*f2,
         expected_probability = ifelse(multiply, expected_probability*2, expected_probability),
         method = "bag of words") %>% 
  select(glottocode, pairs, observed_probability, expected_probability, method) ->
  probabilities_bag_of_words
glimpse(probabilities_bag_of_words)

unnested_andic_featured_with_hash %>% 
  full_join(pure_counts) %>% 
  rename(f1 = frequency) %>% 
  full_join(pure_counts, by = c("glottocode" = "glottocode", "next_segment" = "segment")) %>% 
  rename(f2 = frequency) %>% 
  group_by(glottocode) %>% 
  mutate(observed_probability = n/sum(n, na.rm = TRUE),
         expected_probability = f1*f2,
         method = "markov chain",
         pairs = str_c(segment, " ", next_segment)) %>% 
  select(glottocode, pairs, observed_probability, expected_probability, method) ->
  probabilities_markov_chain
glimpse(probabilities_markov_chain)
```


And now everything can be merged:

```{r, fig.height=9, fig.width=7}
probabilities_bag_of_words %>% 
  bind_rows(probabilities_markov_chain) %>% 
  ggplot(aes(observed_probability, expected_probability, label = pairs))+
  geom_point()+
  ggrepel::geom_text_repel()+
  geom_abline(intercept = 0, slope = 1, linetype = 2) +
  facet_grid(glottocode~method, scales = "free")
```

Hurrah! Dots are around the `y = x` line!
